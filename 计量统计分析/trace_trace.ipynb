{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "from tqdm import tqdm\n",
    "\n",
    "# 参数设定\n",
    "city = 'shanghai'\n",
    "time = [2018, 9, 21]\n",
    "\n",
    "GRID_SIZE = 50  # meter\n",
    "target_dt = datetime.datetime(time[0], time[1], time[2], 8, 0)\n",
    "target_hours = list(range(8, 21))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 区域边界\n",
    "if city == 'beijing':\n",
    "    lon_l, lon_r, lat_b, lat_u = 115.43, 117.52, 39.44, 41.05\n",
    "if city == 'shanghai':\n",
    "    lon_l, lon_r, lat_b, lat_u = 120.836619, 122.165824, 30.631414, 31.7 #31.883925\n",
    "if city == 'shenzhen':\n",
    "    lon_l, lon_r, lat_b, lat_u = 113.70, 114.70, 22.45, 22.85\n",
    "GRID_SIZE = 50  # Meter\n",
    "\n",
    "# 经纬度步长计算\n",
    "earth_radius = 6378137.0\n",
    "pi = 3.1415926535897932384626\n",
    "meter_per_degree = earth_radius * pi / 180.0\n",
    "lat_step = GRID_SIZE * (1.0 / meter_per_degree)\n",
    "ratio = np.cos((lat_b + lat_u) * np.pi / 360)\n",
    "lon_step = lat_step / ratio\n",
    "lat_split = int(np.ceil((lat_u - lat_b) / lat_step))\n",
    "lon_split = int(np.ceil((lon_r - lon_l) / lon_step))\n",
    "\n",
    "# 起始时间（小时偏移起点）\n",
    "t0 = datetime.datetime.strptime('20180101 00:00:00', \"%Y%m%d %H:%M:%S\")\n",
    "\n",
    "# 读取函数\n",
    "def read_from_text(file):\n",
    "    for line in file:\n",
    "        yield line.strip('\\r\\n').split('\\t')\n",
    "\n",
    "# 映射回真实经纬度（用于可视化时反查）\n",
    "def index_to_lon(x_idx):\n",
    "    return lon_l + x_idx * lon_step\n",
    "\n",
    "def index_to_lat(y_idx):\n",
    "    return lat_b + y_idx * lat_step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "if time[2] < 10:\n",
    "    TMP = np.load(f'./tmp_sim/tmp_sim_{city}_2018090{str(time[2])}_cube.npy') # tmp_level_matrix\n",
    "else:\n",
    "    TMP = np.load(f'./tmp_sim/tmp_sim_{city}_201809{str(time[2])}_cube.npy') # tmp_level_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing traces: 450695it [03:40, 2047.32it/s]\n"
     ]
    }
   ],
   "source": [
    "t0 = datetime.datetime(2018, 1, 1, 0, 0, 0)\n",
    "\n",
    "target_start = int((target_dt - t0).total_seconds() // 3600)\n",
    "target_end = target_start + 12  # 到 20:00\n",
    "target_hours = list(range(target_start, target_end + 1))  # 13个小时点\n",
    "\n",
    "all_trace_heat_level = []\n",
    "all_trace_step = []\n",
    "\n",
    "all_steps = []\n",
    "all_tmp_start = []\n",
    "all_tmp_end = []\n",
    "all_weeknum = []\n",
    "all_clock = []\n",
    "\n",
    "with open(f'./record/record_{city}.txt', 'r') as file:\n",
    "    for uid, trace in tqdm(read_from_text(file), desc=\"Processing traces\"):\n",
    "        trace = trace.split('|')\n",
    "\n",
    "        t_list = [int(trace[i]) for i in range(0, len(trace), 3)]\n",
    "        x_list = [float(trace[i]) for i in range(1, len(trace), 3)]\n",
    "        y_list = [float(trace[i]) for i in range(2, len(trace), 3)]\n",
    "\n",
    "        if not (min(t_list) <= target_start and max(t_list) >= target_end):\n",
    "            continue  # 不满足插值条件\n",
    "\n",
    "        if not (max(x_list) <= lon_split and max(y_list) <= lat_split):\n",
    "            continue  # 不满足插值条件\n",
    "\n",
    "        # 提取有效点\n",
    "        valid_t = np.array(t_list)\n",
    "        valid_x = np.array(x_list)\n",
    "        valid_y = np.array(y_list)\n",
    "\n",
    "        # 插值坐标\n",
    "        interp_x = np.round(np.interp(target_hours, valid_t, valid_x))\n",
    "        interp_y = np.round(np.interp(target_hours, valid_t, valid_y))\n",
    "\n",
    "        new_x_list, new_y_list = interp_x.tolist(), interp_y.tolist()\n",
    "        # trace_heat_level = [TLM[int(new_y_list[i]), int(new_x_list[i])] for i in range(len(new_x_list))]\n",
    "        # all_trace_heat_level.append(trace_heat_level)\n",
    "\n",
    "        if max(new_x_list) < lon_split and max(new_y_list) < lat_split:\n",
    "            for i in range(11):\n",
    "                all_steps.append(np.sqrt(((new_x_list[i+1]-new_x_list[i])/lon_step)**2 + ((new_y_list[i+1]-new_y_list[i])/lat_step)**2))\n",
    "                all_tmp_start.append(TMP[i, int(new_y_list[i]), int(new_x_list[i])])\n",
    "                all_tmp_end.append(TMP[i+1, int(new_y_list[i+1]), int(new_x_list[i+1])])\n",
    "                all_weeknum.append(5)\n",
    "                all_clock.append(i+8)\n",
    "\n",
    "        trace_step = [np.sqrt(((new_x_list[i+1]-new_x_list[i])/lon_step)**2 + ((new_y_list[i+1]-new_y_list[i])/lat_step)**2) for i in range(len(new_x_list)-1)]\n",
    "        all_trace_step.append(trace_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_steps, all_tmp_start, all_tmp_end, all_weeknum, all_clock = np.array(all_steps), np.array(all_tmp_start), np.array(all_tmp_end), np.array(all_weeknum), np.array(all_clock)\n",
    "\n",
    "np.savez(f'./stata/stata_{city}_{target_dt.strftime(\"%Y%m%d_%H%M\")}.npz', steps=all_steps, tmp_start=all_tmp_start, tmp_end=all_tmp_end, weeknum=all_weeknum, clock=all_clock)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Traffic_LLM_Tsii",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
